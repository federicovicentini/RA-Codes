---
title: "Research Assistantship - Data Collection"
author: "Federico Vicentini"
date: "01/05/2023"
output: pdf_document
bibliography: references.bib
---


```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE)
```

```{r p0, message=FALSE, echo=FALSE}

# Clear the variables
rm(list = ls())



# Install packages
packages <- c("eurostat", "stargazer", "fredr", "kableExtra",
              "here", "knitr", "tinytex", "rmarkdown", "xfun", "pandoc",
              "wbstats", "Rilostat", "sandwich", "dplyr", "urca", "lmtest",
              "haven")
new_packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new_packages)) install.packages(new_packages, repos="https://cran.mirror.garr.it/CRAN/")
invisible(lapply(packages, library, character.only = TRUE))

# Set the working directory to source file location with
# setwd(here::here())
```

# DATA COLLECTION

## Real GDP Data

\par In this first part, we download nominal GDP data and GDP deflator data from 1980 
to 2020 and then we divide it into the 2 section (1980s and 2010s) in order to calculate
means and thus compare it to the data we got in the TTD Presentation.


```{r p1, message=FALSE, echo=FALSE}
library(fredr)
fredr_set_key("5946a6a1c79f3fe49bea4be0ef8e82e8")
gdp = fredr(
  series_id = "GDP",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("2020-12-31"),
  frequency = "a",
  units = "pc1",
  aggregation_method = "eop"
)

gdp1 = fredr(
  series_id = "GDP",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("1990-12-31"),
  frequency = "a",
  units = "pc1",
  aggregation_method = "eop"
)

gdp2 = fredr(
  series_id = "GDP",
  observation_start = as.Date("2011-01-01"),
  observation_end = as.Date("2019-12-31"),
  frequency = "a",
  units = "pc1",
  aggregation_method = "eop"
)

gdp = data.frame(gdp)
gdp1 = data.frame(gdp1)
gdp2 = data.frame(gdp2)

deflator = fredr(
  series_id = "A191RI1Q225SBEA",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("2020-12-31"),
  frequency = "a",
  units="lin",
  aggregation_method = "eop"
)

deflator1 = fredr(
  series_id = "A191RI1Q225SBEA",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("1990-12-31"),
  frequency = "a",
  units="lin",
  aggregation_method = "eop"
)

deflator2 = fredr(
  series_id = "A191RI1Q225SBEA",
  observation_start = as.Date("2011-01-01"),
  observation_end = as.Date("2019-12-31"),
  frequency = "a",
  units="lin",
  aggregation_method = "eop"
)

deflator = data.frame(deflator)
deflator1 = data.frame(deflator1)
deflator2 = data.frame(deflator2)

realgdp = gdp
realgdp$value = realgdp$value - deflator$value
mean(realgdp$value)

realgdp1 = gdp1
realgdp1$value = realgdp1$value - deflator1$value
mean(realgdp1$value)

realgdp2 = gdp2
realgdp2$value = realgdp2$value - deflator2$value
mean(realgdp2$value)



```

```{r p1.1, message=FALSE}
plot(realgdp$date, realgdp$value, type="l")
plot(realgdp1$date, realgdp1$value, type="l")
plot(realgdp2$date, realgdp2$value, type="l")
```

## Labor Share of Output

### "Naive" Labor Share (LS1)

First attempt here is to download the laborshare timeseries from fred.
You can see from the values of the plots that the level of the labor share is 
underestimated if we use LS1. In fact, this approach neglects some important 
aspects, such as the role of self-employed workers and correction to value added 
in the forms of indirect taxes and consumption of fixed capital.

```{r p2.0}
labshare = fredr(
  series_id = "LABSHPUSA156NRUG",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("2020-12-31"),
  frequency = "a"
)

labshare1 = fredr(
  series_id = "LABSHPUSA156NRUG",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("1990-12-31"),
  frequency = "a"
)

labshare2 = fredr(
  series_id = "LABSHPUSA156NRUG",
  observation_start = as.Date("2011-01-01"),
  observation_end = as.Date("2019-12-31"),
  frequency = "a"
)


labshare = data.frame(labshare)

labshare1 = data.frame(labshare1)

labshare2 = data.frame(labshare2)


plot(labshare$date, labshare$value, type="l")
plot(labshare1$date,labshare1$value, type="l")
plot(labshare2$date,labshare2$value, type= "l")

```



### Guerriero Index

This is precisely why we tried to replicate the laborshare measure provided by 
{@guerriero2019}, defined as:

$$LS6 = \frac{compensation\;of\;employees * 
\left(\frac{workforce-employers}{employees}\right)}
{value\;added-ind.\;taxes-fixed\;cap.\;cons.}$$


Data is retrieved from Ilostat R package API and (@dataunorg)


```{r p2.1, message=FALSE, echo=FALSE}
#API key for bls is: 7b39505b098044f886d056883d2bd925
#library(blsAPI)

#s=wb_search("compensation of employees")
comp=wb_data(country="US","GC.XPN.COMP.CN")

#s=fredr_series_search_text("compensation")
#View(s)

labforce1=read.csv("civilianlaborforce.csv", sep=",")
labforce1=subset(labforce1, labforce1$Period=="M12")

nomgdp = fredr(
  series_id = "GDP",
  observation_start = as.Date("1981-01-01"),
  observation_end = as.Date("2020-12-31"),
  frequency = "a",
  units = "lin",
  aggregation_method = "eop"
)


#This should be the correct indicator to use for the labor force level
labforce=get_ilostat("EAP_TEAP_SEX_AGE_NB_A")
labforce=subset(labforce, labforce$indicator=="EAP_TEAP_SEX_AGE_NB"&
                          labforce$ref_area=="USA"&
                          labforce$classif1=="AGE_AGGREGATE_TOTAL"&
                          labforce$sex=="SEX_T"&
                          labforce$time>=1980)
toc=get_ilostat_toc()



# Assume your dataframe is called "my_df" and your time column is called "time"
# Sort the dataframe in ascending order of time
labforce <- labforce %>% arrange(labforce$time)
#plot(labforce1$Value-labforce$obs_value)

#Download and filter the dataset with all employed by status
database=get_ilostat("EMP_TEMP_SEX_AGE_STE_NB_A")


empl=subset(database, database$indicator=="EMP_TEMP_SEX_AGE_STE_NB"&
                  database$ref_area=="USA"&
                  database$classif1=="AGE_AGGREGATE_TOTAL"&
                  database$classif2 == "STE_AGGREGATE_TOTAL"&
                  database$sex=="SEX_T"&
                  database$time>=1980)

#To get only databaseoyees, filter for STE_ICSE93_1
emplee=subset(database, database$indicator=="EMP_TEMP_SEX_AGE_STE_NB"&
                      database$ref_area=="USA"&
                      database$classif1=="AGE_AGGREGATE_TOTAL"&
                      database$classif2 == "STE_ICSE93_1"&
                      database$sex=="SEX_T"&
                      database$time>=1980)

#Filter for STE_ICSE93_3
icse93_3=subset(database, database$indicator=="EMP_TEMP_SEX_AGE_STE_NB"&
                      database$ref_area=="USA"&
                      database$classif1=="AGE_AGGREGATE_TOTAL"&
                      database$classif2 == "STE_ICSE93_3"&
                      database$sex=="SEX_T"&
                      database$time>=1980)

#Filter for STE_ICSE93_5
icse93_5=subset(database, database$indicator=="EMP_TEMP_SEX_AGE_STE_NB"&
                      database$ref_area=="USA"&
                      database$classif1=="AGE_AGGREGATE_TOTAL"&
                      database$classif2 == "STE_ICSE93_5"&
                      database$sex=="SEX_T"&
                      database$time>=1980)

#Filter for STE_AGGREGATE_SLF
aggslf=subset(database, database$indicator=="EMP_TEMP_SEX_AGE_STE_NB"&
                      database$ref_area=="USA"&
                      database$classif1=="AGE_AGGREGATE_TOTAL"&
                      database$classif2 == "STE_AGGREGATE_SLF"&
                      database$sex=="SEX_T"&
                      database$time>=1980)


#empl = select(empl, time, obs_value)
#names(empl)[2]="empl"

emplee = select(emplee, time, obs_value)
names(emplee)[2]="emplee"

icse93_3 = select(icse93_3, time, obs_value)
names(icse93_3)[2]="icse93_3"

icse93_5 = select(icse93_5, time, obs_value)
names(icse93_5)[2]="icse93_5"

aggslf = select(aggslf, time, obs_value)
names(aggslf)[2]="aggslf"

labforce = select(labforce, time, obs_value)
names(labforce)[2]="labforce"

mergemp <- empl %>%
            merge(labforce, by = "time") %>%
            merge(emplee, by = "time") %>%
            merge(icse93_3, by = "time") %>%
            merge(icse93_5, by = "time") %>%
            merge(aggslf, by = "time")
            
toc=get_ilostat_toc()

# Calculate the number of employers as aggslf - icse93_3 - icse93_5
# this is under the assumption that icse93_4 is negligible
# in fact is around 8k workers for the US economy as a whole

#mergemp$emplrs = mergemp$aggslf - mergemp$icse93_3 - mergemp$icse93_5

# This is not a feasible way to do it, let's stick to LS5 indicator
# instead of LS6


```

For lack of available data on the structure of the labor force in the US
prior to the introduction of the ICSE93 standard, we will use LS5 instead of
the LS6 index, defined as:

$$LS6 = \frac{compensation\;of\;employees * 
\left(\frac{workforce}{employees}\right)}
{value\;added-ind.\;taxes-fixed\;cap.\;cons.}$$

Below you can find also an example of the result we would get by trying to 
compute LS6 too.

Note: since (@guerriero2019) says that "Data on the composition of the workforce is not 
always available for every year. When absent, it is assumed to be the same as in the 
previous year (Gollin 2002). This is a realistic assumption (Askenazy 2003), given 
that the composition of the workforce is relatively constant over time.", and since we
have data on the composition of the workforce from 1994 onward, we will assume that 
in years preceding 1994, workforce composition is the same. Below, you can find a plot
of workforce/employees for 1994 onward, where you can see that the figure is pretty stable.
However, instead of taking 1994 value and projecting backward, I found it better to 
make an average for the period 1994-2000 and then project that figure backward.

Note2: since there are 2 different time series for SNA data, coming from two different
accounting standards (SNA93 and SNA08), we tried 2 approaches. First, we tried to find
a conversion factor between those 2 standards (using first lags in order not to have 
spurious regressions), but this approach leads to a big jump in the data around the
cutoff year. Thus, the second method was just to keep the newer standard for years after
1995, and the old one for years prior. This is probably what @guerriero2019 did in the paper,
since the results look similar (albeit different since we use LS5 and not LS6). This
is the method I selected in the end.

```{r p2.12, message=FALSE}
# For lack of available data, we will use  LS5 and not LS6
#Now, calculate the multiplier of the compensation for every year

mergemp=mergemp[-c(28:29),]

mergemp$mult = (mergemp$labforce)/mergemp$emplee
mergemp$mult6 = (mergemp$labforce-mergemp$icse93_3)/mergemp$emplee

plot(mergemp$time,mergemp$mult,
  main = "Total Workforce / Number of Employees",
  typ="l")

# Now, add the other years by:

multtrain=mergemp$mult[c(1:7)]
simmult=mean(multtrain)
simmult=rep(simmult, 14)
mult=append(simmult, mergemp$mult)

mult6train=mergemp$mult6[c(1:7)]
simmult6=mean(mult6train)
simmult6=rep(simmult6, 14)
mult6=append(simmult6, mergemp$mult6)

#plot(mult)

#Now retrieve data from the un on aggregates
un = read.csv("un-sna-aggregates.txt", sep=";")
names(un)[6]="time"
un = un[order(un$time), ]



#Use the time period of the interregnum (1995-2011), and maybe cut in two (1995-2008)
#Regression with sna2008 as dependent var and sna1993 as regressor
#Coefficient will be our conversion factor.
#Evaluate the model, then check if it can replicate the other series
#and check for violations of assumptions

#Apply to convert the vintage period


findconversion = function(s1,s2){
    lag_s1 <- lag(s1, n=1)
    model <- lm(s1 ~ lag_s1)
    # Check coefficient of lagged variable
    resid <- residuals(model)
    # Perform the Augmented Dickey-Fuller (ADF) test on residuals
    adf_test <- ur.df(resid, type = "drift")
    # Print the test results
    #print(summary(adf_test))
    lag_s2 <- lag(s2, n=1)
    #stargazer(model, type="text")
    model <- lm(s2 ~ lag_s2)
    # Check coefficient of lagged variable
    resid <- residuals(model)
    # Perform the Augmented Dickey-Fuller (ADF) test on residuals
    adf_test <- ur.df(resid, type = "drift")
    # Print the test results
    #print(summary(adf_test))
    #stargazer(model, type="text")
    s1=s1-lag(s1, n=1)
    s2=s2-lag(s2, n=1)
    train = lm(s1 ~ s2)
    #stargazer(train, type = "text")
    coef = train$coefficients
    return(coef)
}

# First is the fixed cap cons, then gross value added
# then compensation and lastly indirect taxes


codelist = c("K.1", "B.1*g", "D.1", "D.2-D.3")

codenames = c("time","fcc", "gdp", "wages", "ind_tax")

ts=data.frame(seq(1980,2020,1))


for(i in 1:length(codelist)){
  ts93 = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 100 & un$time <= 2011 & un$time >= 1995)
  ts08 = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 1000 & un$time <= 2011 & un$time >= 1995)
  tsold = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 100 & un$time < 1995)
  tsnew = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 1000 & un$time >= 1995)
  coef = findconversion(ts08$Value, ts93$Value)
  simts08 = tsold$Value * coef[2] + coef[1]
  addts=c(simts08, tsnew$Value)
  ts[,i+1]=addts
  #plot(ts[,1], addts, type = "o")
}

tsb=data.frame(seq(1980,2020,1))


for(i in 1:length(codelist)){
  tsnew = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 1000 & un$time >= 1995)
  tsold = subset(un, un$SNA93.Item.Code == codelist[i] &
                      un$Series == 100 & un$time < 1995)
  addts=c(tsold$Value, tsnew$Value)
  tsb[,i+1]=addts
}


names(ts) = codenames
names(tsb) = codenames

ts$mult=mult
tsb$mult=mult
tsb$mult6=mult6

ts$labshare=(ts$wages*ts$mult)/(ts$gdp-ts$ind_tax-ts$fcc)
tsb$labshare=(tsb$wages*tsb$mult)/(tsb$gdp-tsb$ind_tax-tsb$fcc)
tsb$labshare6=(tsb$wages*tsb$mult6)/(tsb$gdp-tsb$ind_tax-tsb$fcc)
#plot(ts$time, ts$labshare)
plot(tsb$time, tsb$labshare, main="Labor Share of Output (LS5)",
                             type="l",
                             xlab="Time",
                             ylab="LS5")
plot(tsb$time, tsb$labshare6, main="Labor Share of Output (LS6)",
                              type="l",
                              xlab="Time",
                              ylab="LS6")

period1=tsb[c(2:11),]
labshmean1=mean(period1$labshare)
labshmean1*100

labsh6mean1=mean(period1$labshare6)
labsh6mean1*100

period2=tsb[c(32:40),]
labshmean2=mean(period2$labshare)
labshmean2*100

labsh6mean2=mean(period2$labshare6)
labsh6mean2*100

labsh11=mean(tsb$labshare[c(32)])
labsh11

labsh611=mean(tsb$labshare6[c(32)])
labsh611


(labshmean2-labshmean1)*100

(labsh6mean2-labsh6mean1)*100

```



## Price Markup

Price markup is computed according to @deloecker2020, using the replication
file related to the paper and extracting the time series of aggregate markup
presented as the main finding of the paper itself.

```{r mk,  message=FALSE}
mkts=read.csv("markup.csv", sep=",")

mkts = subset(mkts, year %in% c(1980:2016))

mkts80 = subset(mkts,  year %in% c(1981:1990) )

avg80 = mean(mkts80$MARKUP_spec1)
avg80

mkts10 = subset(mkts,  year %in% c(2011:2016) )

avg10 = mean(mkts10$MARKUP_spec1)
avg10

plot(mkts$year,mkts$MARKUP_spec1, type="l", col="blue")
```

# Market Concentration

```{r mktconc, message=FALSE}
compustat <- data.frame(read_dta("leancompustat.dta"))
compustat <- filter(compustat, fyear>=1980 & fyear<=2019)
compustat$sector=as.factor(compustat$sector)
compustat$naics3=as.factor(compustat$naics3)
library(dplyr)

# Step 1: Calculate cr4, cr20 and HHI with naics4 sector sales and empl
compustat <- compustat %>%
  group_by(fyear) %>%
  mutate(total_sales = sum(sale))%>%
  mutate(total_emp = sum(emp))%>%
  group_by(fyear, naics4) %>%
  mutate(sector_sales = sum(sale)) %>%
  mutate(sector_emp = sum(emp)) %>%
  mutate(ratiosal = (sale/sector_sales)*100) %>%
  mutate(ratioemp = (emp/sector_emp)*100) %>%
  mutate(sectorweight4 = sector_sales/total_sales)%>%
  mutate(sectorweight4emp = sector_emp / total_emp) %>%
  mutate(rank4 = dense_rank(desc(sale))) %>%
  mutate(rank4emp = dense_rank(desc(emp))) %>%
  mutate(population4 = n()) %>%
  mutate(n4cr4sal = sum(ifelse(rank4<=4, sale, 0))/sector_sales) %>%
  mutate(n4cr20sal = sum(ifelse(rank4<=20, sale, 0))/sector_sales) %>%
  mutate(n4cr4emp = sum(ifelse(rank4emp<=4, emp, 0))/sector_emp) %>%
  mutate(n4cr20emp = sum(ifelse(rank4emp<=20, emp, 0))/sector_emp) %>%
  mutate(n4hhisal = sum(ratiosal^2)) %>%
  mutate(n4hhiemp = sum(ratioemp^2))

# Step 2: Calculate cr4 and cr20 with naics3 sector sales and empl
compustat <- compustat %>%
  group_by(fyear, naics3) %>%
  mutate(sector_sales3 = sum(sale)) %>%
  mutate(sector_emp3 = sum(emp)) %>%
  mutate(ratiosal3 = (sale/sector_sales3)*100) %>%
  mutate(ratioemp3 = (emp/sector_emp3)*100) %>%
  mutate(sectorweight3 = sector_sales3/total_sales)%>%
  mutate(sectorweight3emp = sector_emp3 / total_emp) %>%
  mutate(rank3 = dense_rank(desc(sale))) %>%
  mutate(rank3emp = dense_rank(desc(emp))) %>%
  mutate(population3 = n()) %>%
  mutate(n3cr4sal = sum(ifelse(rank3<=4, sale, 0))/sector_sales3) %>%
  mutate(n3cr20sal = sum(ifelse(rank3<=20, sale, 0))/sector_sales3) %>%
  mutate(n3cr4emp = sum(ifelse(rank3emp<=4, emp, 0))/sector_emp3) %>%
  mutate(n3cr20emp = sum(ifelse(rank3emp<=20, emp, 0))/sector_emp3) %>%
  mutate(n3hhisal = sum(ratiosal3^2)) %>%
  mutate(n3hhiemp = sum(ratioemp3^2))

  
# Aggregate database with cr4 by naics2 with naics4 aggregation and sales
n4aggcr <- compustat %>%
  group_by(fyear, naics4) %>%
  summarize(cr4sal = n4cr4sal,cr20sal=n4cr20sal, cr4emp=n4cr4emp, cr20emp=n4cr20emp,
            naics1=naics1, naics2 = naics2, sectorweight = sectorweight4, 
            sectorweightemp=sectorweight4emp, sector = sector,
            hhiemp=n4hhiemp, hhisal=n4hhisal) %>%
  group_by(fyear, naics2) %>%
  summarize(cr4sal = weighted.mean(cr4sal, sectorweight), sector = sector, 
            cr20sal = weighted.mean(cr20sal, sectorweight),
            cr4emp = weighted.mean(cr4emp, sectorweightemp),
            cr20emp = weighted.mean(cr20emp, sectorweightemp),
            hhisal = weighted.mean(hhisal, sectorweight),
            hhiemp = weighted.mean(hhiemp, sectorweightemp))

n3aggcr <- compustat %>%
  group_by(fyear, naics3) %>%
  summarize(cr4sal = n3cr4sal,cr20sal=n3cr20sal, cr4emp=n3cr4emp, cr20emp=n3cr20emp,
            naics1=naics1, naics2 = naics2, sectorweight = sectorweight3, 
            sectorweightemp=sectorweight3emp, sector = sector, 
            hhiemp=n3hhiemp, hhisal=n3hhisal) %>%
  group_by(fyear, naics2) %>%
  summarize(cr4sal = weighted.mean(cr4sal, sectorweight), sector = sector, 
            cr20sal = weighted.mean(cr20sal, sectorweight),
            cr4emp = weighted.mean(cr4emp, sectorweightemp),
            cr20emp = weighted.mean(cr20emp, sectorweightemp),
            hhisal = weighted.mean(hhisal, sectorweight),
            hhiemp = weighted.mean(hhiemp, sectorweightemp))



attach(compustat)

library(ggplot2)

#Position of the legend
pos = c(0.85, 0.1)

# Plot of CR4 with naics4 aggregation

ggplot(n4aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = cr4sal, linetype = "CR4 Sal")) +
  geom_line(aes(y = cr4emp, linetype = "CR4 Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "CR4", 
        title = "Time Series of CR4 by Sector (aggregation by Naics 4)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")

#Plot of CR20 with naics4 aggregation

ggplot(n4aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = cr20sal, linetype = "CR20 Sal")) +
  geom_line(aes(y = cr20emp, linetype = "CR20 Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "CR20", 
        title = "Time Series of CR20 by Sector (aggregation by Naics 4)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")


#Plot of HHI with naics4 aggregation

ggplot(n4aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = hhisal, linetype = "HHI Sal")) +
  geom_line(aes(y = hhiemp, linetype = "HHI Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "HHI", 
        title = "Time Series of HHI by Sector (aggregation by Naics 4)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")

# Plot of CR4 with naics3 aggregation

ggplot(n3aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = cr4sal, linetype = "CR4 Sal")) +
  geom_line(aes(y = cr4emp, linetype = "CR4 Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "CR4", 
        title = "Time Series of CR4 by Sector (aggregation by Naics 3)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")

#Plot of CR20 with naics3 aggregation

ggplot(n3aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = cr20sal, linetype = "CR20 Sal")) +
  geom_line(aes(y = cr20emp, linetype = "CR20 Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "CR20", 
        title = "Time Series of CR20 by Sector (aggregation by Naics 3)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")

#Plot of HHI with naics3 aggregation

ggplot(n3aggcr, aes(x = fyear, color = naics2)) +
  geom_line(aes(y = hhisal, linetype = "HHI Sal")) +
  geom_line(aes(y = hhiemp, linetype = "HHI Emp")) +
  facet_wrap(~ naics2, scales = "free_y") +
  labs( x = "Year", y = "HHI", 
        title = "Time Series of HHI by Sector (aggregation by Naics 3)", linetype = "") +
  scale_linetype_manual(values = c("solid", "dotted"), labels = c("Sales", "Employment")) +
  theme_minimal() +
  guides(color = "none") +
  theme(legend.position = pos, legend.box = "horizontal")

# Use the same aggregation scheme as Autor et al. so:
# all others is sic1 = 8 or 7 or 0 or 4
```






# References
